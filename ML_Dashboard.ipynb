{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac3b7332-c32a-4429-9b09-049bf82351be",
   "metadata": {},
   "source": [
    "\n",
    "<img align=\"right\" width=\"125\" src=\"https://www.ou.nl/documents/40554/3255217/Logo_OU.jpg\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<center> <font size =\"6\" color='red'> Machine Learning Training Dashboard </font></center>\n",
    "<br> \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ba72b",
   "metadata": {},
   "source": [
    "Model Development dashboard \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55993b31-13e9-44aa-92fa-e7fffe29ef12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.red_label { color:red }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.blue_label { color:blue }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "        function showHint(event) {\n",
       "            const btn = event.target;\n",
       "            const uid = btn.dataset.uid;\n",
       "            const hints = JSON.parse(btn.dataset.hints);\n",
       "            let index = parseInt(btn.dataset.index);\n",
       "\n",
       "            const container = document.getElementById(\"hint-container-\" + uid);\n",
       "\n",
       "            if (index < hints.length) {\n",
       "                const hintHTML = `<p><b>Hint ${index + 1}:</b> ${hints[index]}</p>`;\n",
       "                container.insertAdjacentHTML('beforeend', hintHTML);\n",
       "                btn.dataset.index = index + 1;\n",
       "            } else {\n",
       "                container.insertAdjacentHTML('beforeend', \"<p><i>No more hints available.</i></p>\");\n",
       "                btn.disabled = true;\n",
       "                btn.style.opacity = 0.6;\n",
       "            }\n",
       "        }\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .task-box, .subtask-section {\n",
       "                max-width: 300px;\n",
       "                margin: 10px 0;\n",
       "                padding: 10px;\n",
       "                border: 1px solid #ccc;\n",
       "                border-radius: 5px;\n",
       "                font-size: 14px;\n",
       "            }\n",
       "            .status-todo { background-color: #f8f8f8; }\n",
       "            .status-ready { background-color: lightyellow; }\n",
       "            .status-inprogress { background-color: lightblue; }\n",
       "            .status-done { background-color: lightgreen; }\n",
       "            .status-incorrect { background-color: #FF6666; }\n",
       "            .hint-box { margin-top: 5px; font-style: italic; color: #333; }\n",
       "            .hint-button {\n",
       "                background-color: #28a745;\n",
       "                color: white;\n",
       "                border: none;\n",
       "                padding: 5px 10px;\n",
       "                border-radius: 4px;\n",
       "                cursor: pointer;\n",
       "                margin-top: 5px;\n",
       "            }\n",
       "            .hint-button:hover {\n",
       "                background-color: #218838;\n",
       "            }\n",
       "            details > summary {\n",
       "                cursor: pointer;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1a5351243f4d0a9f244381d881e96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(Text(value='', description='User ID:'), Label(value='Terms: All aâ€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### @title ML Dashboard\n",
    "from datetime import datetime\n",
    "import io\n",
    "from IPython.display import clear_output,HTML, display\n",
    "from ipytree import Tree, Node\n",
    "from ipywidgets import *\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "online_version = False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "drive = None\n",
    "\n",
    "if online_version:\n",
    "    display(HTML(\"\"\"\n",
    "    <style>\n",
    "    .status-todo .p-Collapse-header {\n",
    "        background-color: lightyellow;\n",
    "    }\n",
    "\n",
    "    .status-done .p-Collapse-header {\n",
    "        background-color: lightgreen;\n",
    "    }\n",
    "                  \n",
    "    .status-inprogress .p-Collapse-header {\n",
    "        background-color: lightskyblue;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"))\n",
    "    \n",
    "    !git clone https://github.com/muratfirat78/ML_Dashboard &> /dev/null\n",
    "    os.chdir('/content/ML_Dashboard')\n",
    "\n",
    "    from google.colab import auth\n",
    "    from controller.controller import Controller\n",
    "    from googleapiclient.discovery import build\n",
    "    import googleapiclient.http\n",
    "    import random\n",
    "    import numpy as np\n",
    "    \n",
    "    class GoogleDrive:\n",
    "      def __init__(self):\n",
    "          auth.authenticate_user()\n",
    "          self.drive_service = build('drive', 'v3')\n",
    "          self.folderid = '1pN1jFF5tcDxrfQRdTQrHDNvvxRLRbI69'\n",
    "          self.userid = None\n",
    "    \n",
    "      def get_folder(self, userid):\n",
    "        query = f\"name='{userid}' and '{self.folderid}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "        results = self.drive_service.files().list(q=query, fields=\"files(id)\").execute()\n",
    "        files = results.get('files', [])\n",
    "    \n",
    "        if files:\n",
    "            return files[0]['id']\n",
    "      \n",
    "      def download(self, file_id, file_name, userid):\n",
    "        request = self.drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "        #create the userid folder if not existing\n",
    "        path = os.path.join('drive', str(userid))\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(path, file_name)\n",
    "\n",
    "        fh = io.FileIO(f\"{file_path}\", 'wb')\n",
    "        downloader = googleapiclient.http.MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "          status, done = downloader.next_chunk()\n",
    "\n",
    "      def get_performances(self,userid):\n",
    "        folderid = self.get_folder(userid)\n",
    "        query = f\"'{folderid}' in parents and trashed=false\"\n",
    "        results = self.drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "        files = results.get('files', [])\n",
    "        \n",
    "        if not os.path.exists('/content/ML_Dashboard/drive/' + str(userid)):\n",
    "            os.makedirs('/content/ML_Dashboard/drive/' + str(userid))\n",
    "          \n",
    "        for file in files:\n",
    "          if not os.path.exists('./drive/' + userid + '/' + file['name']):\n",
    "            self.download(file['id'], file['name'], userid)\n",
    "    \n",
    "      def login_correct(self,userid):\n",
    "        query = f\"name='{userid}' and '{self.folderid}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "        results = self.drive_service.files().list(q=query, fields=\"files(id)\").execute()\n",
    "        if len(results['files']) > 0:\n",
    "          return True\n",
    "        else:\n",
    "          return False\n",
    "\n",
    "      def register(self):\n",
    "        if self.userid !=None:\n",
    "          return \"User already exists, your username is: \" + self.userid\n",
    "\n",
    "        query = f\"'{self.folderid}' in parents and mimeType='application/vnd.google-apps.folder' and trashed = false and 'me' in owners\"\n",
    "        results = self.drive_service.files().list(q=query,pageSize=1000,fields='files(id, name)').execute()\n",
    "        files = results.get('files', [])\n",
    "\n",
    "        if len(files) > 0:\n",
    "          return \"User exists, your username is: \" + files[0]['name']\n",
    "        else:\n",
    "          userid = None\n",
    "          while True:\n",
    "            userid = str(random.randint(10000, 99999))\n",
    "            query2 = f\"name='{userid}' and '{self.folderid}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "            results2 = self.drive_service.files().list(q=query2,pageSize=1000,fields=\"files(name)\").execute()\n",
    "            files2 = results2.get('files', [])\n",
    "            if len(files2) > 0:\n",
    "              continue\n",
    "            else:\n",
    "              file_metadata = {\n",
    "                'name': userid,\n",
    "                'mimeType': 'application/vnd.google-apps.folder',\n",
    "                'parents': [self.folderid]\n",
    "              }\n",
    "              file = self.drive_service.files().create(body=file_metadata, fields='id').execute()\n",
    "              self.userid = userid\n",
    "              return \"User created, your userid is: \" + userid\n",
    "        \n",
    "    \n",
    "      def to_serializable(self, obj):\n",
    "          if isinstance(obj, np.generic):\n",
    "              return obj.item()\n",
    "          elif isinstance(obj, dict):\n",
    "              return {k: self.to_serializable(v) for k, v in obj.items()}\n",
    "          elif isinstance(obj, list):\n",
    "              return [self.to_serializable(v) for v in obj]\n",
    "          elif isinstance(obj, tuple):\n",
    "              return tuple(self.to_serializable(v) for v in obj)\n",
    "          else:\n",
    "              return obj\n",
    "\n",
    "\n",
    "      def upload_log(self, result, userid, timestamp):\n",
    "        with open('./drive/'+ userid + '/' + timestamp +\n",
    "                  '.txt', 'w') as f:\n",
    "          f.write(str(self.to_serializable(result)))\n",
    "    \n",
    "        folderid = self.get_folder(userid)\n",
    "\n",
    "        #see if the file already exists\n",
    "        query = f\"name='{timestamp}.txt' and '{folderid}' in parents and trashed = false\"\n",
    "        response = self.drive_service.files().list(q=query, spaces='drive', fields='files(id)').execute()\n",
    "        files = response.get('files', [])\n",
    "    \n",
    "        media = googleapiclient.http.MediaFileUpload('./drive/'+ userid + '/' + timestamp + '.txt', mimetype=\"text/plain\", resumable=True)\n",
    "\n",
    "        if files:\n",
    "            #file already exists, overwrite\n",
    "            file_id = files[0]['id']\n",
    "            uploaded_file = self.drive_service.files().update(\n",
    "                fileId=file_id,\n",
    "                media_body=media\n",
    "            ).execute()\n",
    "        else:\n",
    "            #file does not exist yet, create\n",
    "            file_metadata = {\n",
    "            \"name\": timestamp + \".txt\",\n",
    "            \"parents\": [folderid]\n",
    "            }\n",
    "            \n",
    "            uploaded_file = self.drive_service.files().create(\n",
    "                body=file_metadata,\n",
    "                media_body=media,\n",
    "                fields=\"id\"\n",
    "            ).execute()\n",
    "    \n",
    "    drive = GoogleDrive()\n",
    "    \n",
    "    from controller.controoller import Controller\n",
    "    controller = Controller(drive, online_version)\n",
    "else:\n",
    "    from controller.controller import Controller\n",
    "    controller = Controller(drive, online_version)\n",
    "\n",
    "ui = controller.get_ui()\n",
    "\n",
    "ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ba0177-a5e5-4ad5-9148-e6569c73f638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Logistic Regression (aka logit, MaxEnt) classifier.\n",
       "\n",
       "In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
       "scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
       "cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
       "(Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
       "'sag', 'saga' and 'newton-cg' solvers.)\n",
       "\n",
       "This class implements regularized logistic regression using the\n",
       "'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
       "that regularization is applied by default**. It can handle both dense\n",
       "and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
       "floats for optimal performance; any other input format will be converted\n",
       "(and copied).\n",
       "\n",
       "The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
       "with primal formulation, or no regularization. The 'liblinear' solver\n",
       "supports both L1 and L2 regularization, with a dual formulation only for\n",
       "the L2 penalty. The Elastic-Net regularization is only supported by the\n",
       "'saga' solver.\n",
       "\n",
       "Read more in the :ref:`User Guide <logistic_regression>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "penalty : {'l1', 'l2', 'elasticnet', None}, default='l2'\n",
       "    Specify the norm of the penalty:\n",
       "\n",
       "    - `None`: no penalty is added;\n",
       "    - `'l2'`: add a L2 penalty term and it is the default choice;\n",
       "    - `'l1'`: add a L1 penalty term;\n",
       "    - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
       "\n",
       "    .. warning::\n",
       "       Some penalties may not work with some solvers. See the parameter\n",
       "       `solver` below, to know the compatibility between the penalty and\n",
       "       solver.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "       l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
       "\n",
       "dual : bool, default=False\n",
       "    Dual (constrained) or primal (regularized, see also\n",
       "    :ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation\n",
       "    is only implemented for l2 penalty with liblinear solver. Prefer dual=False when\n",
       "    n_samples > n_features.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    Tolerance for stopping criteria.\n",
       "\n",
       "C : float, default=1.0\n",
       "    Inverse of regularization strength; must be a positive float.\n",
       "    Like in support vector machines, smaller values specify stronger\n",
       "    regularization.\n",
       "\n",
       "fit_intercept : bool, default=True\n",
       "    Specifies if a constant (a.k.a. bias or intercept) should be\n",
       "    added to the decision function.\n",
       "\n",
       "intercept_scaling : float, default=1\n",
       "    Useful only when the solver 'liblinear' is used\n",
       "    and self.fit_intercept is set to True. In this case, x becomes\n",
       "    [x, self.intercept_scaling],\n",
       "    i.e. a \"synthetic\" feature with constant value equal to\n",
       "    intercept_scaling is appended to the instance vector.\n",
       "    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
       "\n",
       "    Note! the synthetic feature weight is subject to l1/l2 regularization\n",
       "    as all other features.\n",
       "    To lessen the effect of regularization on synthetic feature weight\n",
       "    (and therefore on the intercept) intercept_scaling has to be increased.\n",
       "\n",
       "class_weight : dict or 'balanced', default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one.\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *class_weight='balanced'*\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
       "    data. See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'\n",
       "\n",
       "    Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
       "    To choose a solver, you might want to consider the following aspects:\n",
       "\n",
       "        - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
       "          and 'saga' are faster for large ones;\n",
       "        - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
       "          'lbfgs' handle multinomial loss;\n",
       "        - 'liblinear' is limited to one-versus-rest schemes.\n",
       "        - 'newton-cholesky' is a good choice for `n_samples` >> `n_features`,\n",
       "          especially with one-hot encoded categorical features with rare\n",
       "          categories. Note that it is limited to binary classification and the\n",
       "          one-versus-rest reduction for multiclass classification. Be aware that\n",
       "          the memory usage of this solver has a quadratic dependency on\n",
       "          `n_features` because it explicitly computes the Hessian matrix.\n",
       "\n",
       "    .. warning::\n",
       "       The choice of the algorithm depends on the penalty chosen.\n",
       "       Supported penalties by solver:\n",
       "\n",
       "       - 'lbfgs'           -   ['l2', None]\n",
       "       - 'liblinear'       -   ['l1', 'l2']\n",
       "       - 'newton-cg'       -   ['l2', None]\n",
       "       - 'newton-cholesky' -   ['l2', None]\n",
       "       - 'sag'             -   ['l2', None]\n",
       "       - 'saga'            -   ['elasticnet', 'l1', 'l2', None]\n",
       "\n",
       "    .. note::\n",
       "       'sag' and 'saga' fast convergence is only guaranteed on features\n",
       "       with approximately the same scale. You can preprocess the data with\n",
       "       a scaler from :mod:`sklearn.preprocessing`.\n",
       "\n",
       "    .. seealso::\n",
       "       Refer to the User Guide for more information regarding\n",
       "       :class:`LogisticRegression` and more specifically the\n",
       "       :ref:`Table <Logistic_regression>`\n",
       "       summarizing solver/penalty supports.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       Stochastic Average Gradient descent solver.\n",
       "    .. versionadded:: 0.19\n",
       "       SAGA solver.\n",
       "    .. versionchanged:: 0.22\n",
       "        The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
       "    .. versionadded:: 1.2\n",
       "       newton-cholesky solver.\n",
       "\n",
       "max_iter : int, default=100\n",
       "    Maximum number of iterations taken for the solvers to converge.\n",
       "\n",
       "multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
       "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
       "    label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
       "    across the entire probability distribution, *even when the data is\n",
       "    binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
       "    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
       "    and otherwise selects 'multinomial'.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "       Stochastic Average Gradient descent solver for 'multinomial' case.\n",
       "    .. versionchanged:: 0.22\n",
       "        Default changed from 'ovr' to 'auto' in 0.22.\n",
       "\n",
       "verbose : int, default=0\n",
       "    For the liblinear and lbfgs solvers set verbose to any positive\n",
       "    number for verbosity.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to True, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of CPU cores used when parallelizing over classes if\n",
       "    multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
       "    set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
       "    not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
       "    context. ``-1`` means using all processors.\n",
       "    See :term:`Glossary <n_jobs>` for more details.\n",
       "\n",
       "l1_ratio : float, default=None\n",
       "    The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
       "    used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
       "    to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
       "    to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
       "    combination of L1 and L2.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "\n",
       "classes_ : ndarray of shape (n_classes, )\n",
       "    A list of class labels known to the classifier.\n",
       "\n",
       "coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
       "    Coefficient of the features in the decision function.\n",
       "\n",
       "    `coef_` is of shape (1, n_features) when the given problem is binary.\n",
       "    In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
       "    to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
       "\n",
       "intercept_ : ndarray of shape (1,) or (n_classes,)\n",
       "    Intercept (a.k.a. bias) added to the decision function.\n",
       "\n",
       "    If `fit_intercept` is set to False, the intercept is set to zero.\n",
       "    `intercept_` is of shape (1,) when the given problem is binary.\n",
       "    In particular, when `multi_class='multinomial'`, `intercept_`\n",
       "    corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
       "    outcome 0 (False).\n",
       "\n",
       "n_features_in_ : int\n",
       "    Number of features seen during :term:`fit`.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
       "    Names of features seen during :term:`fit`. Defined only when `X`\n",
       "    has feature names that are all strings.\n",
       "\n",
       "    .. versionadded:: 1.0\n",
       "\n",
       "n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
       "    Actual number of iterations for all classes. If binary or multinomial,\n",
       "    it returns only 1 element. For liblinear solver, only the maximum\n",
       "    number of iteration across all classes is given.\n",
       "\n",
       "    .. versionchanged:: 0.20\n",
       "\n",
       "        In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
       "        ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "SGDClassifier : Incrementally trained logistic regression (when given\n",
       "    the parameter ``loss=\"log_loss\"``).\n",
       "LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The underlying C implementation uses a random number generator to\n",
       "select features when fitting the model. It is thus not uncommon,\n",
       "to have slightly different results for the same input data. If\n",
       "that happens, try with a smaller tol parameter.\n",
       "\n",
       "Predict output may not match that of standalone liblinear in certain\n",
       "cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
       "in the narrative documentation.\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       "L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
       "    Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
       "    http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
       "\n",
       "LIBLINEAR -- A Library for Large Linear Classification\n",
       "    https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
       "\n",
       "SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
       "    Minimizing Finite Sums with the Stochastic Average Gradient\n",
       "    https://hal.inria.fr/hal-00860051/document\n",
       "\n",
       "SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
       "        :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
       "        for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
       "\n",
       "Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
       "    methods for logistic regression and maximum entropy models.\n",
       "    Machine Learning 85(1-2):41-75.\n",
       "    https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.datasets import load_iris\n",
       ">>> from sklearn.linear_model import LogisticRegression\n",
       ">>> X, y = load_iris(return_X_y=True)\n",
       ">>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
       ">>> clf.predict(X[:2, :])\n",
       "array([0, 0])\n",
       ">>> clf.predict_proba(X[:2, :])\n",
       "array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
       "       [9.7...e-01, 2.8...e-02, ...e-08]])\n",
       ">>> clf.score(X, y)\n",
       "0.97...\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\murat\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     LogisticRegressionCV"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree,neighbors,linear_model,ensemble,svm\n",
    "\n",
    "linear_model.LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736d518-68f4-4cfc-a5e0-bcd8a177e552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
